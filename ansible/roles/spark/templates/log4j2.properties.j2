# Ansible Managed - Spark Log4j2 Configuration

# Root logger level
rootLogger.level = INFO
rootLogger.appenderRef.stdout.ref = console
rootLogger.appenderRef.file.ref = file

# Console Appender
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_ERR
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# File Appender
appender.file.type = RollingFile
appender.file.name = file
appender.file.fileName = /var/log/spark/spark.log
appender.file.filePattern = /var/log/spark/spark-%d{yyyy-MM-dd}-%i.log.gz
appender.file.layout.type = PatternLayout
appender.file.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
appender.file.policies.type = Policies
appender.file.policies.time.type = TimeBasedTriggeringPolicy
appender.file.policies.time.interval = 1
appender.file.policies.time.modulate = true
appender.file.policies.size.type = SizeBasedTriggeringPolicy
appender.file.policies.size.size = 100MB
appender.file.strategy.type = DefaultRolloverStrategy
appender.file.strategy.max = 10

# Quiet noisy loggers
logger.jetty.name = org.sparkproject.jetty
logger.jetty.level = WARN

logger.kafka.name = org.apache.kafka
logger.kafka.level = WARN

logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = WARN

logger.hive.name = org.apache.hive
logger.hive.level = WARN

logger.parquet.name = org.apache.parquet
logger.parquet.level = ERROR
